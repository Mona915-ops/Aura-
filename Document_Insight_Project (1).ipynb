{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_gozh1gGkWYq"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers langchain langchain-community sentence-transformers pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOKcQkv9wSk8"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login(\"API\")  # paste your token here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdEM5Hb_wk3z"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynn1KX3hww_o"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvKd7JyLw9ei"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(\"AIML FOR NETWORKING_20250702_135552_0000.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = splitter.split_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdY-gyosxLWU"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-278m-multilingual\")\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCrf3JEQxgGP"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"ibm-granite/granite-3.3-2b-instruct\",\n",
        "    huggingfacehub_api_token=\"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\",\n",
        "    model_kwargs={\"temperature\": 0.2, \"max_new_tokens\": 256}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBxxMG66yEkO"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkUlfbA71yVX"
      },
      "outputs": [],
      "source": [
        "def answer_question(question):\n",
        "    if not question:\n",
        "        return \"Please type a question.\"\n",
        "    return qa.run(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqCVt5RK2j1X"
      },
      "outputs": [],
      "source": [
        "iface = gr.Interface(\n",
        "    fn=answer_question,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask a question about the documents...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Document QA with AI\",\n",
        "    description=\"Type any question related to the documents and get an AI-generated answer.\"\n",
        ")\n",
        "\n",
        "# Launch the interface in Colab\n",
        "iface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
